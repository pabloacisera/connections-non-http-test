
# AI-Socket Terminal Bridge

Una arquitectura Cliente-Servidor de alto rendimiento basada en TCP Sockets que permite la interacciÃ³n con modelos de Inteligencia Artificial (Gemini API) mediante una interfaz de lÃ­nea de comandos, manteniendo persistencia dual en RAM/SQLite y soportando TLS para comunicaciones seguras.

---

## ğŸ¯ Â¿Para quiÃ©n es esta aplicaciÃ³n?

### Casos de Uso Principales

**1. Desarrolladores Backend & DevOps**
- IntegraciÃ³n de IA en scripts de automatizaciÃ³n sin dependencias pesadas de HTTP
- Testing de modelos de lenguaje en entornos de producciÃ³n con control total del socket
- Despliegue en servidores sin interfaz grÃ¡fica (headless servers)

**2. Investigadores & Data Scientists**
- ExperimentaciÃ³n con diferentes modelos de Gemini sin cambiar cÃ³digo
- AnÃ¡lisis de latencia y throughput en comunicaciones de bajo nivel
- Prototipado rÃ¡pido de agentes conversacionales con memoria persistente

**3. Administradores de Sistemas**
- GestiÃ³n remota de infraestructura con asistencia IA
- Logs y debugging en tiempo real con contexto histÃ³rico
- Alternativa ligera a interfaces web para servidores de producciÃ³n

**4. Estudiantes & Educadores**
- Aprendizaje de arquitecturas cliente-servidor con casos reales
- ComprensiÃ³n de protocolos de bajo nivel (TCP/IP, TLS)
- ImplementaciÃ³n de sistemas con estado y gestiÃ³n de sesiones

---

## ğŸ—ï¸ Arquitectura del Sistema

### Modelo de ComunicaciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         TCP Socket (TLS)          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cliente   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Servidor   â”‚
â”‚  (CLI)      â”‚         Puerto 65432              â”‚  (Python)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                                          â”‚
                                                          â–¼
                                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                   â”‚ Gemini API   â”‚
                                                   â”‚ (MÃºltiples   â”‚
                                                   â”‚  Modelos)    â”‚
                                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes Principales

#### 1. **Servidor (`server.py`)**
- **Multithreading**: GestiÃ³n concurrente de mÃºltiples clientes mediante `threading.Thread`
- **IdentificaciÃ³n Ãšnica**: Hash SHA-256 de la IP del cliente como identificador inmutable
- **Orquestador IA**: Proxy entre cliente y Gemini API con gestiÃ³n de historial
- **Seguridad TLS**: Soporte opcional de cifrado con certificados autofirmados
- **Persistencia Dual**: 
  - **Capa 1 (RAM)**: Diccionario `chat_sessions` para acceso ultra-rÃ¡pido
  - **Capa 2 (SQLite)**: Tabla `messages` para persistencia entre reinicios

#### 2. **Cliente (`client.py`)**
- **CLI Interactiva**: Interfaz de comandos con efecto typewriter
- **Dual Mode**: 
  - **Modo Comando**: GestiÃ³n de conexiÃ³n y configuraciÃ³n
  - **Modo IA**: Chat interactivo full-duplex con el modelo
- **TLS AutomÃ¡tico**: DetecciÃ³n y aplicaciÃ³n de cifrado segÃºn `.env`

#### 3. **Sistema de Memoria (`memory_manage.py`)**
- **ResÃºmenes AutomÃ¡ticos**: Cuando la RAM excede 100MB, Gemini auto-resume la conversaciÃ³n
- **Contexto HistÃ³rico**: RecuperaciÃ³n de resÃºmenes previos al iniciar sesiÃ³n
- **LÃ­mite de ResÃºmenes**: Mantiene Ãºltimos 50 resÃºmenes por cliente en SQLite

#### 4. **GestiÃ³n de Modelos (`models.py`)**
- **CachÃ© de Modelos**: Evita peticiones redundantes a Gemini API (5 min TTL)
- **Filtrado Inteligente**: Excluye modelos de embedding, audio y video
- **Hot-Swapping**: Cambio de modelo sin reiniciar el servidor

---

## ğŸ” Seguridad TLS

### GeneraciÃ³n de Certificados Autofirmados

```bash
# Generar clave privada y certificado (vÃ¡lido 365 dÃ­as)
openssl req -x509 -newkey rsa:4096 -keyout server.key -out server.crt \
  -days 365 -nodes -subj "/CN=localhost"
```

### ConfiguraciÃ³n en `.env`

```env
USE_TLS=true
SSL_CERTFILE=server.crt
SSL_KEYFILE=server.key
```

### Flujo de Handshake TLS

1. Cliente solicita conexiÃ³n â†’ `socket.connect()`
2. Servidor envuelve socket â†’ `ssl_context.wrap_socket()`
3. NegociaciÃ³n de cipher suite (AES-256-GCM recomendado)
4. VerificaciÃ³n de certificado (deshabilitada en cliente para autofirmados)
5. Canal cifrado establecido âœ…

---

## ğŸ“Š Persistencia de Datos

### Esquema de Base de Datos (SQLite)

```sql
-- Mensajes individuales
CREATE TABLE messages (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    client_id TEXT NOT NULL,
    role TEXT NOT NULL,  -- 'user' | 'model'
    content TEXT NOT NULL,
    timestamp DATETIME NOT NULL
);

-- ResÃºmenes de conversaciones
CREATE TABLE summaries (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    client_id TEXT NOT NULL,
    summary_text TEXT NOT NULL,
    created_at DATETIME NOT NULL
);
```

### Estrategia de Memoria

```python
# Capa 1: RAM (acceso O(1))
chat_sessions[client_id] = {
    "messages": [
        {"role": "user", "content": "...", "timestamp": datetime},
        {"role": "model", "content": "...", "timestamp": datetime}
    ]
}

# Capa 2: SQLite (persistencia)
save_message(client_id, role, content)  # Ejecuta INSERT asÃ­ncrono
```

### Control de TamaÃ±o

- **LÃ­mite RAM**: 100 MB por sesiÃ³n
- **AcciÃ³n al exceder**: Auto-resumen vÃ­a Gemini + limpieza de RAM + guardado en SQLite
- **Prompt de resumen**:
```python
"ActÃºa como un gestor de memoria. Resume de forma tÃ©cnica y concisa 
esta conversaciÃ³n para que pueda ser retomada en el futuro sin perder 
informaciÃ³n clave..."
```

---

## ğŸ® Protocolo de Comandos

### Comandos Disponibles

| Comando | DescripciÃ³n | Respuesta |
|---------|-------------|-----------|
| `INFO` | Detalles de conexiÃ³n | `ID: abc123... \| IP: 192.168.1.10 \| Puerto: 54321 \| Conectado: 14:30:25` |
| `LIST-MODELS` | Modelos disponibles | Lista numerada + modelo actual |
| `CHANGE-MODEL` | Cambiar modelo activo | MenÃº interactivo â†’ ConfirmaciÃ³n |
| `IA` | Activar modo chat | Entra en bucle IA |
| `EXIT` / `QUIT` | Desconectar | Cierra socket |

### Flujo de Cambio de Modelo

```
Cliente: CHANGE-MODEL
Servidor: [EnvÃ­a menÃº con 15 modelos]
Cliente: 3
Servidor: âœ… Modelo cambiado a: gemini-2.0-flash-exp
         [Limpia historial de RAM]
```

---

## ğŸš€ InstalaciÃ³n y Uso

### Requisitos

```bash
# Python 3.8+
pip install -r requirements.txt
```

**Dependencias principales**:
- `google-genai==1.56.0` - SDK oficial de Gemini
- `python-dotenv==1.2.1` - GestiÃ³n de variables de entorno
- `pyOpenSSL==25.3.0` - Soporte TLS

### ConfiguraciÃ³n

**Archivo `.env`**:
```env
IP_SERVER=192.168.1.10
PORT_SERVER=65432
GEMINI_API_KEY=AIzaSy...  # Tu API key de Google AI Studio

# Seguridad
USE_TLS=true
SSL_CERTFILE=server.crt
SSL_KEYFILE=server.key

# Base de Datos
DB_PATH=ai_bridge.db
```

### EjecuciÃ³n

```bash
# Terminal 1: Servidor
python server.py
# [SYSTEM] Iniciando servidor en 192.168.1.10:65432
# [SYSTEM] TLS: HABILITADO
# [SYSTEM] 12 modelos cargados
# [SYSTEM] Escuchando conexiones...

# Terminal 2: Cliente
python client.py
# [CLIENT] Conectando a 192.168.1.10:65432...
# [CLIENT] ConexiÃ³n TLS establecida
# [SERVER] ID:a3f8b2e1... | Conectado a 192.168.1.10:65432
```

### Ejemplo de SesiÃ³n

```
Comando > LIST-MODELS

=== MODELOS DISPONIBLES ===
  1. gemini-2.0-flash
  2. gemini-2.0-flash-exp
  3. gemini-2.5-flash
  4. gemini-pro
...
ğŸ“Œ Modelo actual: gemini-2.0-flash

Comando > IA
[SERVER] Modo IA activado. Escribe 'back' para salir.

IA > Explica quÃ© es un socket TCP en 50 palabras
============================================================
Un socket TCP es una abstracciÃ³n de software que representa
un punto final de comunicaciÃ³n bidireccional entre dos 
procesos en una red. Utiliza el protocolo TCP para garantizar
entrega ordenada y sin errores mediante handshakes, nÃºmeros
de secuencia y acknowledgements.
============================================================

IA > back
[SERVER] Saliendo del modo IA...
```

---

## ğŸ”§ Especificaciones TÃ©cnicas

### GestiÃ³n de Identidad

```python
def create_client_id(ip_address):
    """Genera ID Ãºnico basado en SHA-256 de la IP"""
    return hashlib.sha256(ip_address.encode()).hexdigest()
```

**Ventajas**:
- Inmutable durante la sesiÃ³n
- Sin colisiones (probabilidad < 1e-60)
- No requiere base de datos para generaciÃ³n

### GestiÃ³n de Contexto IA

```python
# Preparar historial para Gemini API
gemini_history = []
for msg in chat_sessions[client_id]["messages"]:
    gemini_history.append(
        types.Content(
            role=msg["role"], 
            parts=[types.Part(text=msg["content"])]
        )
    )

# Enviar con contexto completo
chat = gemini_client.chats.create(
    model=f"models/{current_model}",
    history=gemini_history
)
response = chat.send_message(user_input)
```

### Manejo de Errores

```python
try:
    sock.settimeout(30)  # Timeout de 30 segundos
    sock.connect((IP_SERVER, PORT_SERVER))
except ConnectionRefusedError:
    print("[ERROR] Servidor no disponible")
except socket.timeout:
    print("[ERROR] Timeout de conexiÃ³n")
except ssl.SSLError as e:
    print(f"[ERROR] Fallo TLS: {e}")
```

---

## ğŸ“ˆ Ventajas sobre REST/HTTP

| Aspecto | TCP Socket (Este Proyecto) | REST API |
|---------|---------------------------|----------|
| **Latencia** | ~5-10ms (conexiÃ³n persistente) | ~50-100ms (handshake por request) |
| **Overhead** | MÃ­nimo (raw bytes) | Headers HTTP (~200-500 bytes/request) |
| **Estado** | Nativo (socket abierto) | Stateless (requiere tokens/cookies) |
| **Streaming** | Full-duplex nativo | Requiere SSE/WebSockets |
| **Memoria** | Control total (RAM + SQLite) | Depende del framework |

---

## ğŸ› ï¸ Estructura del Proyecto

```
ai-socket-bridge/
â”œâ”€â”€ server.py              # Servidor principal
â”œâ”€â”€ client.py              # Cliente CLI
â”œâ”€â”€ requirements.txt       # Dependencias Python
â”œâ”€â”€ .env                   # Variables de entorno
â”œâ”€â”€ server.crt             # Certificado TLS
â”œâ”€â”€ server.key             # Clave privada TLS
â”œâ”€â”€ ai_bridge.db           # Base de datos SQLite
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ security.py        # Manejo TLS
â”‚   â”œâ”€â”€ models.py          # GestiÃ³n de modelos Gemini
â”‚   â””â”€â”€ commands.py        # Comandos del cliente
â”œâ”€â”€ helpers/
â”‚   â””â”€â”€ memory_manage.py   # Sistema de memoria
â””â”€â”€ database/
    â””â”€â”€ database.py        # InicializaciÃ³n SQLite
```

---

## ğŸ¤ Contribuciones

Las mejoras sugeridas incluyen:
- ImplementaciÃ³n de autenticaciÃ³n JWT sobre TLS
- Soporte para mÃºltiples APIs (OpenAI, Claude, etc.)
- Dashboard web opcional para monitoreo
- ExportaciÃ³n de conversaciones a Markdown/JSON

---

## ğŸ“œ Licencia

Este proyecto es de cÃ³digo abierto. Consulta el archivo `LICENSE` para mÃ¡s detalles.

---

## ğŸ”— Enlaces Ãštiles

- [DocumentaciÃ³n Gemini API](https://ai.google.dev/gemini-api/docs)
- [Python Socket Programming](https://docs.python.org/3/library/socket.html)
- [OpenSSL Certificate Generation](https://www.openssl.org/docs/man1.1.1/man1/req.html)

---

**VersiÃ³n**: 0.2.0  
**Ãšltima actualizaciÃ³n**: Enero 2026  
**Mantenedor**: testdeveloperrandom@gmail.com
